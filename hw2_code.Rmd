---
title: "hw2_code"
author: "YuechenLiu"
date: "9/30/2020"
output: html_document
---
```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

```{r}
trashwheel_df =
  read_xlsx(
    "./Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = 'Mr. Trash Wheel',
    range = cell_cols('A:N')) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

```{r}
precip_2018 = 
  read_excel(
    "./Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = '2018 Precipitation',
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = '2017 Precipitation',
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018,precip_2017) 

left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data.


## Problem 2

Read the NYC Transit dataset.

```{r}
NYC_df = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada)
```

##Summary

This dataset describes detailed information for NYC Subway. Firstly, I loaded the data. Then I used janitor to make variables look more succinct. The select function was applied to keep only the variables that we want. In order to combine the 11 routes, we need to convert numerical factors to logical ones.

The dataset contains variables including line, station name, station latitude, station longitude, entry, vending, entrance type, ada, route number and route name, or we can summary them as `r names(NYC_df)`. There are a total of `r nrow(NYC_df)` rows and `r ncol(NYC_df)` columns in our final dataset. 


##Using these data:
There are `r nrow(NYC_df %>% distinct (line, station_name))` distinct stations.
There are `r nrow(filter(NYC_df,ada == 'TRUE' ) %>% distinct(line, station_name))` stations that are ADA compliant.

This dataset is a little bit better than raw data, but not tidy enough.

Manage the data.

```{r}
NYC_df = 
  mutate(NYC_df, entry = ifelse(entry%in%c('YES'), TRUE, FALSE)) %>%
  mutate_at(vars(route8:route11), as.character) %>%
  pivot_longer(
    route1:route11,
    names_to = 'route_name',
    values_to = 'route_number',
  ) 
```

The proportion of station entrances / exits without vending allow entrance is `r nrow(filter(NYC_df, vending == "NO", entry == "TRUE"))` divide by `r nrow(filter(NYC_df, vending == "NO"))` (which the answer is ~37.7%)
 
```{r}
NYC_A = filter(NYC_df, route_number == 'A')
```
There are `r count(distinct (NYC_A, line, station_name))` stations that serve A train.
Of the stations that serve the A train, there are `r filter(NYC_A, ada == 'TRUE') %>% distinct (line, station_name) %>% nrow` stations that are ADA compliant.



##Problem 3

The pols-month dataset:

```{r}
PM = read.csv(
  './pols-month.csv') %>% 
  janitor::clean_names() %>% 
  separate(mon, c('year','month','day')) %>%
  mutate(
    month = recode(month, '01' = 'January', '02' = 'February', '03' = 'March', '04' = 'April', '05' = 'May', '06' = 'June', '07' = 'July', '08' = 'August', '09' = 'September', '10' = 'October', '11' = 'November', '12' ='December')) %>% 
  mutate(
    president = recode(prez_gop, '0' = 'democrat', '1' = 'republic', '2' = 'republic')
  ) %>% 
  select(-'prez_dem', -'prez_gop', -'day')
```

The snp dataset:

```{r}
SNP = read.csv(
  './snp.csv') %>%
  janitor::clean_names() %>%
  separate(date, c('month','day','year')) %>%
    mutate(
    month = recode(month, '1' = 'January', '2' = 'February', '3' = 'March', '4' = 'April', '5' = 'May', '6' = 'June', '7' = 'July', '8' = 'August', '9' = 'September', '10' = 'October', '11' = 'November', '12' ='December')) %>% 
  arrange( year, month ) %>% 
  relocate(year, month ) %>% 
  select(-'day')
```

The unemployment dataset:

```{r}
UN = read.csv(
  './unemployment.csv') %>% 
  janitor::clean_names() %>%
  pivot_longer(jan:dec,
               names_to = 'month',
               values_to = 'unemployment') %>% 
  mutate(
    month = recode(month, 'jan' = 'January', 'feb' = 'February', 'mar' = 'March', 'apr' = 'April', 'may' = 'May', 'jun' = 'June', 'jul' = 'July', 'aug' = 'August', 'sep' = 'September', 'oct' = 'October', 'nov' = 'November', 'dec' ='December')) %>% 
  mutate_at(vars(year), as.character)

```

Merging SNP into POLS, then merging Unemployment:
```{r}
Merged = 
  left_join(PM,SNP,by=c('year','month')) %>% 
  left_join(UN,by=c('year','month'))
```

##Summary
The pols-month dataset tells us number of different government officials and which party the president was in at specific times.
The SNP dataset tells us the closing values of the S&P stock index on the associated dates.
The Unemployment dataset tells us percentage of unemployment every month of the year since 1948.

The final result dataset, which is called Merged, has `r nrow(Merged)` rows and `r ncol(Merged)` columns.
It's year range is from `r (head(Merged$year,1))` to `r (tail(Merged$year,1))`.

It has the following variables: `r ls(Merged)`, among them, we used year and month as key variables when merging them.
















